{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["6KTmJVE6xltq","rfY1FClZxmBH","JDuiZ2iw68cN","PR6cBU8vbS51","tgozYUCfx563"],"authorship_tag":"ABX9TyNKG3w69vJ3LTUs776TBAwg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["Things to do \n","\n","\n","1.   make the index look better (done)\n","2.   finish the speed up GRU block\n","3.   upload it with data onto Github\n","---------------------------------------------\n","\n","\n","tips for training\n","\n","https://danijar.com/tips-for-training-recurrent-neural-networks/\n"],"metadata":{"id":"WWPfKSZS8kS3"}},{"cell_type":"markdown","source":["# **Name country prediction using GRU**\n","\n"],"metadata":{"id":"6KTmJVE6xltq"}},{"cell_type":"code","execution_count":6,"metadata":{"id":"fOjeMejmxjCD","executionInfo":{"status":"ok","timestamp":1676803435093,"user_tz":-60,"elapsed":434,"user":{"displayName":"liam pan","userId":"04789786804288950917"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","\n","import gzip # file reading\n","import csv # file reading\n"]},{"cell_type":"markdown","source":["# **Data Preparations**"],"metadata":{"id":"rfY1FClZxmBH"}},{"cell_type":"markdown","source":["### Implement Dataloader\n","\n","--------------------------------\n","a simple way to make dictionary"],"metadata":{"id":"SDFYcpA1dW2w"}},{"cell_type":"code","source":["List1 =[\"a\", \"b\", \"c\"]\n","List2 =[2,1,3]\n","List3 =dict(zip(List1, List2))\n","List3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"taRkt5vUtj-n","executionInfo":{"status":"ok","timestamp":1676803436034,"user_tz":-60,"elapsed":498,"user":{"displayName":"liam pan","userId":"04789786804288950917"}},"outputId":"212462dc-22da-48f2-c6a2-976e57bc464e"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'a': 2, 'b': 1, 'c': 3}"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["#### Test case of each single code block"],"metadata":{"id":"aaYclNbKtaR5"}},{"cell_type":"code","source":[" # test case of each single code block\n","\n","file_read = [['Maclean','English'],['Vajnichy','Russian'],['Usami','Japanese'],['Jackson','English'],['Zimmermann','Germany']]\n","\n","# Read countries and names as list from data\n","countries = [item[1]for item in file_read]\n","# print(countries)\n","names = [item[0]for item in file_read]\n","\n","countries_list = list(sorted(set(countries)))  #  latter for index to country\n","# print(country_list_test)\n","\n","# Create a set from list \n","countries_set = set(countries)\n","\n","\n","# iterate over the set to create a dictionary :countries_dic\n","\n","def get_countries_dic (countries_set):\n","  countries_dic={}\n","\n","  i = 0  # let class be 0 indexed\n","  for country in countries_set:\n","    countries_dic[country] = i\n","    i+=1\n","  return countries_dic\n","# Test get_countries_dic\n","w = get_countries_dic(countries_set)\n","print('countries_dic:',w)\n","print('*'*30)\n","\n","# get item(idx)\n","countries_dic = get_countries_dic(countries_set)\n","def get_item(idx):\n","\n","  return names[idx],countries_dic[countries[idx]]\n","# Test\n","\n","print('test of get_item')\n","for idx in range(len(file_read)):\n","  naem,coun = get_item(idx)\n","  print(naem,coun)\n","\n","def get_countries_num():\n","  return len(countries_dic)\n","print('*'*30)\n","print('test of get_countries_num')  \n","get_countries_num()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bg8VP-bddWKe","executionInfo":{"status":"ok","timestamp":1676803436034,"user_tz":-60,"elapsed":23,"user":{"displayName":"liam pan","userId":"04789786804288950917"}},"outputId":"61780537-3d3a-4a98-aa93-87fb28111f43"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["countries_dic: {'Germany': 0, 'English': 1, 'Japanese': 2, 'Russian': 3}\n","******************************\n","test of get_item\n","Maclean 1\n","Vajnichy 3\n","Usami 2\n","Jackson 1\n","Zimmermann 0\n","******************************\n","test of get_countries_num\n"]},{"output_type":"execute_result","data":{"text/plain":["4"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["#### Test of the wraped up class by using self designed debugging data "],"metadata":{"id":"JDuiZ2iw68cN"}},{"cell_type":"code","source":["# wrap them into class NameDataset\n","\n","# using debugging data\n","\n","\n","class NameDataset(Dataset):\n","  def __init__(self,is_train_set=True):\n","\n","    # For debug test_use: uncomment the following\n","    rows = [['Maclean','English'],['Vajnichy','Russian'],['Usami','Japanese'],['Jackson','English'],['Zimmermann','Germany']] # index begin with 1\n","\n","    # read data from file (comment following block while debugging)\n","    # filename = '/content/names_test.csv.gz' if is_train_set else '/content/names_train.csv.gz'\n","    # with gzip.open(filename, 'rt') as f:\n","    #   reader = csv.reader(f)\n","    #   rows = list(reader)\n","\n","    self.countries = [row[1]for row in rows]\n","    self.names = [row[0]for row in rows]\n","    self.countries_list = list(sorted(set(self.countries)))\n","    self.num_countries = len(self.countries_list)\n","    print('*'*30)\n","    print('Comment out when code debugging is passed')\n","    print('countries_list',self.countries_list)       #Comment out when code debugging is passed\n","    self.countries_dic = self.get_countries_dic()\n","\n","    print('self.countries_dic',self.countries_dic)     #Comment out when code debugging is passed\n","\n","  def __getitem__(self,idx):    # get name,country_index by idx\n","\n","    return self.names[idx],self.countries_dic[self.countries[idx]]\n","    #return names[idx],self.countries_list[idx]\n","\n","  def __len__(self):        # get dataset's lenth (how many names are there))\n","    return len(self.names)\n","\n","  def get_countries_dic (self):  # helper funtion get countries_list-index dictionary , countries in ..dic and countries_list are arranged in same order\n","\n","  # can also use enumerate , but more complex\n","\n","    list1 = torch.arange( 0 , self.num_countries ).tolist()   # choose index begin with 1 because data started with index 1\n","    countries_dic = dict(zip(self.countries_list,list1))    # wrong! Should be self.countries_list\n","    return countries_dic\n","\n","  def index2country(self,idx):# map  index of a name to a country in word  \n","    return self.countries_list[idx]   # minus one since countries_list is zero indexed\n","  def getCountriesNum(self):  # get total number of countries \n","    return self.num_countries\n","\n","# instantiate a dataset\n","dataloader_test_1 = NameDataset() \n","\n","# test __getitem__\n","print('*'*30)\n","print('test __getitem__;','expected: Usami,2')\n","print(dataloader_test_1[2])\n","\n","# test index2country()\n","print('*'*30)\n","print('test index2country();','expected: Japanese')\n","print(dataloader_test_1.index2country(dataloader_test_1[2][1]))\n","# test get data set length\n","print('*'*30)\n","print('test getDataset length:' 'expected :5')\n","print(len(dataloader_test_1))\n","# test get num of countries\n","print('*'*30)\n","print('test getCountriesNum:' 'expected :4')\n","print(dataloader_test_1.getCountriesNum())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FwX8VmHZ5EtM","executionInfo":{"status":"ok","timestamp":1676803436034,"user_tz":-60,"elapsed":15,"user":{"displayName":"liam pan","userId":"04789786804288950917"}},"outputId":"018c0e23-cdea-46e7-cce4-f85a12cebe54"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["******************************\n","Comment out when code debugging is passed\n","countries_list ['English', 'Germany', 'Japanese', 'Russian']\n","self.countries_dic {'English': 0, 'Germany': 1, 'Japanese': 2, 'Russian': 3}\n","******************************\n","test __getitem__; expected: Usami,2\n","('Usami', 2)\n","******************************\n","test index2country(); expected: Japanese\n","Japanese\n","******************************\n","test getDataset length:expected :5\n","5\n","******************************\n","test getCountriesNum:expected :4\n","4\n"]}]},{"cell_type":"markdown","source":["#### Test of the wraped up class by actual testing data"],"metadata":{"id":"1u5xPIeS7BJT"}},{"cell_type":"code","source":["# wrap them into class NameDataset\n","\n","# using actual test data\n","\n","\n","class NameDataset(Dataset):\n","  def __init__(self,is_train_set=True):    # Caution\n","\n","    # For debug test_use: uncomment the following\n","    # rows = [['Maclean','English'],['Vajnichy','Russian'],['Usami','Japanese'],['Jackson','English'],['Zimmermann','Germany']]\n","\n","    # read data from file (comment following block while debugging)\n","    filename =  '/content/names_train.csv.gz' if is_train_set else '/content/names_test.csv.gz'\n","    with gzip.open(filename, 'rt') as f:\n","      reader = csv.reader(f)\n","      rows = list(reader)\n","\n","    self.countries = [row[1]for row in rows]\n","    self.names = [row[0]for row in rows]\n","\n","\n","    self.countries_list = list(sorted(set(self.countries)))\n","    self.num_countries = len(self.countries_list)\n","    print('*'*30)\n","    print('Comment out when code debugging is passed')\n","    print('countries_list',self.countries_list)       #Comment out when code debugging is passed\n","    self.countries_dic = self.get_countries_dic()\n","    print('self.countries_dic',self.countries_dic)     #Comment out when code debugging is passed\n","\n","  def __getitem__(self,idx):\n","\n","    return self.names[idx],self.countries_dic[self.countries[idx]]\n","    #return names[idx],self.countries_list[idx]\n","\n","  def __len__(self):\n","    return len(self.names)\n","\n","  def get_countries_dic (self):\n","\n","    list1 = torch.arange(0,self.num_countries).tolist()  # index begin with 0 , when index began with 1 softmax hav to have dim= 1+ num_classes\n","    countries_dic = dict(zip(self.countries_list,list1))\n","    return countries_dic\n","\n","  def index2country(self,idx):\n","    return self.countries_list[idx]\n","  def getCountriesNum(self):\n","    #return self.num_countries\n","    return self.num_countries\n","\n","# instantiate a dataset\n","dataloader_test_2 = NameDataset(is_train_set=False) \n","\n","# test __getitem__\n","print('*'*30)\n","print('test __getitem__;[9]','expected: Bohac\",\"2\"')\n","print(dataloader_test_2[9])\n","print('test __getitem__;[1]','expected: Abl\",\"2\"') \n","print(dataloader_test_2[1])\n","# test index2country()\n","print('*'*30)\n","print('test index2country();','expected: Czech')\n","print(dataloader_test_2.index2country(dataloader_test_2[2][1]))\n","# test get data set length\n","print('*'*30)\n","print('test getDataset length:' 'expected :6700')\n","print(len(dataloader_test_2))\n","# test get num of countries\n","print('*'*30)\n","print('test getCountriesNum:' 'expected :18')\n","print(dataloader_test_2.getCountriesNum())\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UFBy1PuzkN0S","executionInfo":{"status":"ok","timestamp":1676803436035,"user_tz":-60,"elapsed":12,"user":{"displayName":"liam pan","userId":"04789786804288950917"}},"outputId":"b504b581-22c5-4f1d-b819-3b1385c8f799"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["******************************\n","Comment out when code debugging is passed\n","countries_list ['Arabic', 'Chinese', 'Czech', 'Dutch', 'English', 'French', 'German', 'Greek', 'Irish', 'Italian', 'Japanese', 'Korean', 'Polish', 'Portuguese', 'Russian', 'Scottish', 'Spanish', 'Vietnamese']\n","self.countries_dic {'Arabic': 0, 'Chinese': 1, 'Czech': 2, 'Dutch': 3, 'English': 4, 'French': 5, 'German': 6, 'Greek': 7, 'Irish': 8, 'Italian': 9, 'Japanese': 10, 'Korean': 11, 'Polish': 12, 'Portuguese': 13, 'Russian': 14, 'Scottish': 15, 'Spanish': 16, 'Vietnamese': 17}\n","******************************\n","test __getitem__;[9] expected: Bohac\",\"2\"\n","('Borovka', 2)\n","test __getitem__;[1] expected: Abl\",\"2\"\n","('Alt', 2)\n","******************************\n","test index2country(); expected: Czech\n","Czech\n","******************************\n","test getDataset length:expected :6700\n","6700\n","******************************\n","test getCountriesNum:expected :18\n","18\n"]}]},{"cell_type":"code","source":["list1 = torch.arange(1,3).tolist()\n","list1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wzEWus0kCxlW","executionInfo":{"status":"ok","timestamp":1676803436035,"user_tz":-60,"elapsed":8,"user":{"displayName":"liam pan","userId":"04789786804288950917"}},"outputId":"c40135d2-15c7-4ba9-d909-1a23be032150"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1, 2]"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["####**Class NameDataset is working,**\n","\n","\n"],"metadata":{"id":"ft80c-1TrXh1"}},{"cell_type":"markdown","source":["### Create the trainloader and the testloader"],"metadata":{"id":"b8QvbRAPJv8b"}},{"cell_type":"code","source":["\n","class NameDataset(Dataset):\n","  def __init__(self,is_train_set=True):    # Caution\n","\n","    # For debug test_use: uncomment the following\n","    # rows = [['Maclean','English'],['Vajnichy','Russian'],['Usami','Japanese'],['Jackson','English'],['Zimmermann','Germany']]\n","\n","    # read data from file (comment following block while debugging)\n","    filename =  '/content/names_train.csv.gz' if is_train_set else '/content/names_test.csv.gz'\n","    with gzip.open(filename, 'rt') as f:\n","      reader = csv.reader(f)\n","      rows = list(reader)\n","\n","    self.countries = [row[1]for row in rows]\n","    self.names = [row[0]for row in rows]\n","\n","\n","    self.countries_list = list(sorted(set(self.countries)))\n","    self.num_countries = len(self.countries_list)\n","    #print('*'*30)\n","    #print('Comment out when code debugging is passed')\n","    #print('countries_list',self.countries_list)       #Comment out when code debugging is passed\n","    self.countries_dic = self.get_countries_dic()\n","    #print('self.countries_dic',self.countries_dic)     #Comment out when code debugging is passed\n","\n","  def __getitem__(self,idx):\n","\n","    return self.names[idx],self.countries_dic[self.countries[idx]]\n","    #return names[idx],self.countries_list[idx]\n","\n","  def __len__(self):\n","    return len(self.names)\n","\n","  def get_countries_dic (self):\n","\n","    list1 = torch.arange(0,self.num_countries).tolist()  # index begin with 0 , when index began with 1 softmax hav to have dim= 1+ num_classes\n","    countries_dic = dict(zip(self.countries_list,list1))\n","    return countries_dic\n","\n","  def index2country(self,idx):\n","    return self.countries_list[idx]\n","  def getCountriesNum(self):\n","    #return self.num_countries\n","    return self.num_countries"],"metadata":{"id":"qkEA1Cl2Laf8","executionInfo":{"status":"ok","timestamp":1676803436035,"user_tz":-60,"elapsed":5,"user":{"displayName":"liam pan","userId":"04789786804288950917"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["batch_size = 16\n","\n","from torch.utils.data.dataloader import DataLoader\n","\n","trainset = NameDataset(is_train_set=True,)   # Drop_last beacuse: total number of data= 7600 , and 7600 is not Divisible by batch_size=256\n","testset = NameDataset(is_train_set=False)\n","trainloader = DataLoader(trainset,batch_size=batch_size,shuffle=True,drop_last=True) \n","testloader = DataLoader(testset,batch_size=batch_size,shuffle=False,drop_last=True)\n","\n","\n"],"metadata":{"id":"GnGeZBkCrle1","executionInfo":{"status":"ok","timestamp":1676808378230,"user_tz":-60,"elapsed":529,"user":{"displayName":"liam pan","userId":"04789786804288950917"}}},"execution_count":139,"outputs":[]},{"cell_type":"markdown","source":["#### Test of trainloader"],"metadata":{"id":"B77gexcPEvUL"}},{"cell_type":"code","source":["dataiter = iter(trainloader)\n","batch_test, labels_test = next(dataiter)\n","\n","print(len(batch_test))\n","print(batch_test[:10])\n","print(labels_test[:10])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rFneo6WdE1FW","executionInfo":{"status":"ok","timestamp":1676803436605,"user_tz":-60,"elapsed":15,"user":{"displayName":"liam pan","userId":"04789786804288950917"}},"outputId":"d51efb63-d903-4701-d420-0acbf4190b13"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["256\n","('Sheppard', 'Ustimkin', 'AuYong', 'Squires', 'Dikarevsky', 'Bridges', 'Yamlikhanov', 'Mosconi', 'Hastings', 'Tunik')\n","tensor([ 4, 14,  1,  4, 14,  4, 14,  9,  4, 14])\n"]}]},{"cell_type":"markdown","source":["## Implementation of Utility Blocks"],"metadata":{"id":"vxEUmB1u9gdg"}},{"cell_type":"markdown","source":["### Convert name to tensor function: make_tensors ()"],"metadata":{"id":"WllNmxHaCNY_"}},{"cell_type":"markdown","source":["#### Try to get each unit inside that function to work"],"metadata":{"id":"U1vbe04I-YD2"}},{"cell_type":"code","source":["\n","\n","# Para Settings\n","\n","\n","\n","# \n","names = ['Maclean','Vajnichy','Usami']\n","countries1 = ['English','Russian','Japanese']\n","countries = [0,1,2]\n","list2 = [list(string) for string in names]\n","\n","def name2list (name):\n","  arr = [ord(c) for c in name]\n","  return arr, len(arr)\n","\n","\n","sequences_and_lenths=[name2list (name) for name in list2]\n","print('*'*30)\n","print(sequences_and_lenths)\n","\n","name_sequences = [sequence[0] for sequence in sequences_and_lenths]\n","print('*'*30)\n","print(name_sequences)\n","seq_lenths = torch.LongTensor([sequence[1] for sequence in sequences_and_lenths])\n","print('*'*30)\n","print(seq_lenths)\n","\n","\n","countries = torch.Tensor(countries).long() # convert into long tensor\n","\n","\n","print('*'*30)\n","print('countires',countries)\n","\n","\n","# make a zero tensor with size of Batch_size * Seq_len\n","seq_tensor = torch.zeros(len(name_sequences),seq_lenths.max())\n","print('*'*30)\n","print('seq_tensor: ',seq_tensor)\n","print('*'*30)\n","\n","# for i in range(len(name_sequences)):\n","#   seq_tensor[i,:seq_lenths[i]] =  torch.LongTensor(name_sequences[i])  this also works\n","\n","for idx,(seq,seq_len) in enumerate(zip(name_sequences,seq_lenths),0):\n","  seq_tensor[idx,:seq_len] = torch.LongTensor(seq)  # must change to tensor first, otherwise is impossible to align tuple to tensor (error!)\n","\n","print('seq_tensor after padding:')\n","print('',seq_tensor)\n","\n","\n","seq_lenths, perm_idx = seq_lenths.sort(dim=0, descending=True)\n","seq_tensor = seq_tensor[perm_idx]\n","seq_tensor = seq_tensor.int()\n","countries = countries[perm_idx]\n","print('*'*30)\n","print(seq_tensor)\n","print('*'*30)\n","print(countries)\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j9ymtRvAx4ZQ","executionInfo":{"status":"ok","timestamp":1676803436606,"user_tz":-60,"elapsed":15,"user":{"displayName":"liam pan","userId":"04789786804288950917"}},"outputId":"e0174de8-47e0-4f78-9d14-d63d1d882008"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["******************************\n","[([77, 97, 99, 108, 101, 97, 110], 7), ([86, 97, 106, 110, 105, 99, 104, 121], 8), ([85, 115, 97, 109, 105], 5)]\n","******************************\n","[[77, 97, 99, 108, 101, 97, 110], [86, 97, 106, 110, 105, 99, 104, 121], [85, 115, 97, 109, 105]]\n","******************************\n","tensor([7, 8, 5])\n","******************************\n","countires tensor([0, 1, 2])\n","******************************\n","seq_tensor:  tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0.]])\n","******************************\n","seq_tensor after padding:\n"," tensor([[ 77.,  97.,  99., 108., 101.,  97., 110.,   0.],\n","        [ 86.,  97., 106., 110., 105.,  99., 104., 121.],\n","        [ 85., 115.,  97., 109., 105.,   0.,   0.,   0.]])\n","******************************\n","tensor([[ 86,  97, 106, 110, 105,  99, 104, 121],\n","        [ 77,  97,  99, 108, 101,  97, 110,   0],\n","        [ 85, 115,  97, 109, 105,   0,   0,   0]], dtype=torch.int32)\n","******************************\n","tensor([1, 0, 2])\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"ZX2YE9tgZQ2k","executionInfo":{"status":"ok","timestamp":1676803436606,"user_tz":-60,"elapsed":12,"user":{"displayName":"liam pan","userId":"04789786804288950917"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["####  Function Declaration: make_tensors()"],"metadata":{"id":"yr3SerbdNZG2"}},{"cell_type":"code","source":["# make Convert name(list) to tensor\n","gpu_available = torch.cuda.is_available()\n","if gpu_available:\n","    USE_GPU = True \n","    device = \"cuda\" \n","    print(\"Cuda is available\")\n","else: \n","  USE_GPU = False\n","  device = \"cpu\"\n","  print(\"CUDA is not available. Execution time on the cpu is slow.\")\n"," #   For the Purpose of simple implementation latter switch it to True , set False to simplify the debugging process\n","\n","\n","# Test Cases\n","names = ['Maclean','Vajnichy','Usami']\n","#countries1 = ['English','Russian','Japanese']\n","countries = [0,1,2]\n","\n","# Functions called inside make_tensors()\n","def cer(c):                     # this function take char and outputs its asci code\n","  arr = [ ord(character ) for character in c]\n","  return arr, len(arr)\n","\n","def create_tensor(tensor):              # this function moves tensors to cuda , when train on gpu mode is True\n","\n","  if USE_GPU:\n","    device = torch.device(\"cuda:0\")\n","    tensor = tensor.to(device)\n","  return tensor\n","\n","# Functions Declaration: make_tensors()\n","\n","def make_tensors(names, countries):\n","\n","  # convert each name to a sublist consisted of characters\n","  names_inchar = [list(name) for name in names]\n","\n","  # conver each name in a list of characters further to a list of ascii code(indexes)\n","  sequences = [cer(name) for name in names_inchar]\n","\n","  # get name_sequences, seq_lenths seprately\n","  name_sequences  = [sequence[0] for sequence in sequences]\n","  seq_lenths = [sequence[-1] for sequence in sequences]\n","\n","  # Padding the input vector with zero to maximal seq_lenth\n","  seq_tensor = torch.zeros(len(sequences),max(seq_lenths)) # 1. Create a zero tensor with size: batch_size, * maxi. seq_len ,\n","\n","  for idx in range(len(name_sequences )):        # 2. paste each line of name_sequences onto seq_tensor\n","    seq_tensor[idx,: seq_lenths[idx] ] = torch.LongTensor(name_sequences [idx])\n","\n","  # Rearrange outputs tensor in descending order of seq_lenths\n","  seq_lenths = torch.LongTensor(seq_lenths)   # Swtich seq_lenths to tensor type in order to use 'sort' method and for output\n","  seq_lenths, location_idx = seq_lenths.sort(descending=True) # Get the location index from seq_lenths in a descending order\n","  seq_lenths = seq_lenths[location_idx]\n","  seq_tensor = seq_tensor[location_idx]\n","  seq_tensor = seq_tensor.long()\n","\n","  # swtich countries to tensor form\n","  countries = torch.tensor(countries).long()\n","  \n","  return create_tensor(seq_tensor), \\\n","      create_tensor(seq_lenths),\\\n","      create_tensor(countries)\n","\n"],"metadata":{"id":"YgYPOYU-iCS5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676805376303,"user_tz":-60,"elapsed":15,"user":{"displayName":"liam pan","userId":"04789786804288950917"}},"outputId":"72bd3a72-7bad-4271-91ff-0f0b4f30fca8"},"execution_count":77,"outputs":[{"output_type":"stream","name":"stdout","text":["Cuda is available\n"]}]},{"cell_type":"markdown","source":["####Test of make_tensors()"],"metadata":{"id":"Y7pQqhe29wyF"}},{"cell_type":"code","source":["a,b,c = make_tensors(names, countries)\n","\n","print(a)\n","print(b)\n","print(c)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-rw6Zo5qx4vZ","executionInfo":{"status":"ok","timestamp":1676803436606,"user_tz":-60,"elapsed":11,"user":{"displayName":"liam pan","userId":"04789786804288950917"}},"outputId":"eceed306-8b27-4833-ed4a-6c2b2e2f679e"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 86,  97, 106, 110, 105,  99, 104, 121],\n","        [ 77,  97,  99, 108, 101,  97, 110,   0],\n","        [ 85, 115,  97, 109, 105,   0,   0,   0]])\n","tensor([7, 8, 5])\n","tensor([0, 1, 2])\n"]}]},{"cell_type":"markdown","source":["# **Model Buildings**"],"metadata":{"id":"5SN9iaEixmDZ"}},{"cell_type":"markdown","source":["###little demo for testing of embedding layers setting"],"metadata":{"id":"i8kw1BMMUn_R"}},{"cell_type":"markdown","source":["input size of the embeder : ([3, 8])\n","\n","input of the embeder\n","```\n","tensor([[ 86.,  97., 106., 110., 105.,  99., 104., 121.],\n","        [ 77.,  97.,  99., 108., 101.,  97., 110.,   0.],\n","        [ 85., 115.,  97., 109., 105.,   0.,   0.,   0.]])\n","```\n","output size of the embeder([3, 8, 10]) of Batch_size x sqe_len x (embeded)input size \n","\n","-----------------------------------\n","**Caution:**  GRU takes input of seq_L.x batch_Num.x D*Hidden_size by default\n","\n","This means: before feed it to GruCell , the after embeded tensor has to be transposed , or input of the emebedding layer should be transposed \n","\n","\n"],"metadata":{"id":"lTl5PLecXkhi"}},{"cell_type":"code","source":["\n","embedding = torch.nn.Embedding(num_embeddings=129, embedding_dim=10) \n","\n","# First Para:  num_embeddings is the number of indexes (i.e: diemnson of the one-hot vec) that need to be embedded respectively.here it must be greater 128,(121) \n","\n","\n","# Second Para: embedding_dim indicates the size of each embedding vector\n","# a batch of 2 samples of 4 indices each\n","#_________________________________________________\n","\n","#input = torch.LongTensor([[1,2,4,5],[4,3,2,9]]) #  sequen_lenth *  Btach_size *(1 elemnt index)\n","\n","print('*'*20,' Each embedded index is a vector of size embedding_dim','*'*20)\n","embedded = embedding(seq_tensor) # #  sequen_lenth *  Btach_size * embedding_dim\n","print('*'*20,\"Input shape:sequen_lenth *  Btach_size *(1 elemnt index)\",'*'*20)\n","print('Input shape:',seq_tensor.shape)\n","print('Input',seq_tensor)\n","print('*'*20,\"embedded shape:sequen_lenth *  Btach_size * embedding_dim\",'*'*20)\n","print('*'*20,\"embedding_dim = input as one hot vectoc 's size for RNN\",'*'*20)\n","print('embedded: shape:  ',embedded.shape)\n","print('embedded: ',embedded)"],"metadata":{"id":"dIHNanN1UsEa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676803436607,"user_tz":-60,"elapsed":10,"user":{"displayName":"liam pan","userId":"04789786804288950917"}},"outputId":"aba7a68b-c3c7-4444-f210-9cb8761ea95f"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["********************  Each embedded index is a vector of size embedding_dim ********************\n","******************** Input shape:sequen_lenth *  Btach_size *(1 elemnt index) ********************\n","Input shape: torch.Size([3, 8])\n","Input tensor([[ 86,  97, 106, 110, 105,  99, 104, 121],\n","        [ 77,  97,  99, 108, 101,  97, 110,   0],\n","        [ 85, 115,  97, 109, 105,   0,   0,   0]], dtype=torch.int32)\n","******************** embedded shape:sequen_lenth *  Btach_size * embedding_dim ********************\n","******************** embedding_dim = input as one hot vectoc 's size for RNN ********************\n","embedded: shape:   torch.Size([3, 8, 10])\n","embedded:  tensor([[[-0.6946,  1.4719, -0.4625, -0.0352,  0.7955,  0.5219,  0.9349,\n","           1.9550,  0.4870, -1.3420],\n","         [ 1.7260, -1.6912, -0.9874,  0.3145,  0.2664, -0.0886, -1.2795,\n","           0.8871,  0.3717,  1.7194],\n","         [-1.0184, -0.3502,  0.0249,  0.7343, -0.4833,  0.2849, -0.0233,\n","          -0.9896, -1.1507, -0.9455],\n","         [ 0.5622, -0.2432, -0.9819,  0.3963, -2.2775, -0.7060, -0.1364,\n","          -0.1242,  1.3221,  0.1026],\n","         [ 0.3100, -1.2635, -0.3911, -0.9044,  1.0213,  0.4860,  0.0857,\n","          -0.7176,  0.0563, -1.3011],\n","         [-0.6237,  0.3940, -0.3386,  0.5784, -0.3738, -0.6711, -1.1641,\n","           1.1524, -1.0898,  0.5242],\n","         [-0.5359, -1.4698, -0.6680,  0.4393, -0.9533, -1.0711, -0.2861,\n","          -0.1774, -0.9627, -0.5103],\n","         [-0.2525, -0.2751, -0.5186,  0.8838,  1.8007,  0.1592, -1.2072,\n","          -1.6133,  0.4834, -0.6946]],\n","\n","        [[ 1.5983,  0.9836, -0.1475,  0.3516, -0.9424,  0.4435,  0.0135,\n","           0.7303, -0.3411, -0.5479],\n","         [ 1.7260, -1.6912, -0.9874,  0.3145,  0.2664, -0.0886, -1.2795,\n","           0.8871,  0.3717,  1.7194],\n","         [-0.6237,  0.3940, -0.3386,  0.5784, -0.3738, -0.6711, -1.1641,\n","           1.1524, -1.0898,  0.5242],\n","         [ 1.4643,  0.5778, -1.7080,  0.7316,  1.3248,  0.4669,  0.8849,\n","           2.5948,  0.3461,  0.3920],\n","         [-1.3111,  0.1421,  0.1922,  1.3376,  1.3574,  1.3430,  1.3896,\n","          -1.2124,  0.7361,  0.1498],\n","         [ 1.7260, -1.6912, -0.9874,  0.3145,  0.2664, -0.0886, -1.2795,\n","           0.8871,  0.3717,  1.7194],\n","         [ 0.5622, -0.2432, -0.9819,  0.3963, -2.2775, -0.7060, -0.1364,\n","          -0.1242,  1.3221,  0.1026],\n","         [ 1.4251,  0.2225, -0.6296,  1.8316, -1.5980,  0.0603, -0.5690,\n","          -1.2700, -0.7504,  1.4058]],\n","\n","        [[-0.6387, -0.2877,  0.7055,  0.4503,  0.6207, -0.7625, -0.2143,\n","           0.0994,  0.7394, -0.3062],\n","         [ 0.3239, -1.0422,  0.0546,  0.8738, -0.0320, -0.7445, -0.8671,\n","           0.4615,  1.7950,  1.1339],\n","         [ 1.7260, -1.6912, -0.9874,  0.3145,  0.2664, -0.0886, -1.2795,\n","           0.8871,  0.3717,  1.7194],\n","         [ 1.0470, -0.4554,  0.7889,  1.1230,  1.3071,  0.5355,  0.9743,\n","           0.5696,  0.7802,  1.6677],\n","         [ 0.3100, -1.2635, -0.3911, -0.9044,  1.0213,  0.4860,  0.0857,\n","          -0.7176,  0.0563, -1.3011],\n","         [ 1.4251,  0.2225, -0.6296,  1.8316, -1.5980,  0.0603, -0.5690,\n","          -1.2700, -0.7504,  1.4058],\n","         [ 1.4251,  0.2225, -0.6296,  1.8316, -1.5980,  0.0603, -0.5690,\n","          -1.2700, -0.7504,  1.4058],\n","         [ 1.4251,  0.2225, -0.6296,  1.8316, -1.5980,  0.0603, -0.5690,\n","          -1.2700, -0.7504,  1.4058]]], grad_fn=<EmbeddingBackward0>)\n"]}]},{"cell_type":"markdown","source":["### little demo for **GRU CELL** para settings\n","\n","https://pytorch.org/docs/stable/generated/torch.nn.GRU.html"],"metadata":{"id":"BYdo5uguPtgE"}},{"cell_type":"code","source":["import torch\n","batch_size = 1\n","seq_len = 3\n","input_size = 10\n","hidden_size = 2\n","num_layers = 1\n","bidirectional=True\n","\n","if bidirectional==True :\n","  D = 2 \n","else:\n","  D =1\n","print(D)\n","\n","# creae a simple GRU cell\n","cell = torch.nn.GRU(input_size, hidden_size, num_layers,bidirectional=bidirectional)\n","\n","# (seqLen, batchSize, inputSize)\n","inputs = torch.randn( seq_len, batch_size, input_size)\n","hidden = torch.zeros(D* num_layers, batch_size, hidden_size)\n","with torch. no_grad():\n","  out, hidden = cell(inputs, hidden)\n","  print('Output size:','seq_L,Batch , D ∗ Hidden;', out.shape)\n","  print('Output:', out)\n","  print('Hidden size: ','D∗num_layers ,  Hidden;', hidden.shape)\n","  print('Hidden: ', hidden)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cP9unne0Ps5r","executionInfo":{"status":"ok","timestamp":1676803437737,"user_tz":-60,"elapsed":1137,"user":{"displayName":"liam pan","userId":"04789786804288950917"}},"outputId":"01c214bf-bd4c-4115-9234-17ed15ecc293"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["2\n","Output size: seq_L,Batch , D ∗ Hidden; torch.Size([3, 1, 4])\n","Output: tensor([[[-0.3129,  0.1519, -0.0432, -0.6591]],\n","\n","        [[-0.2036, -0.7362,  0.1617, -0.5819]],\n","\n","        [[-0.6972, -0.6472, -0.0059,  0.5109]]])\n","Hidden size:  D∗num_layers ,  Hidden; torch.Size([2, 1, 2])\n","Hidden:  tensor([[[-0.6972, -0.6472]],\n","\n","        [[-0.0432, -0.6591]]])\n"]}]},{"cell_type":"markdown","source":["### create model class"],"metadata":{"id":"UYgc5OHXSDi-"}},{"cell_type":"markdown","source":["![Bidirectional_RNN.png](data:image/png;base64,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)"],"metadata":{"id":"G-jaFQq1xSff"}},{"cell_type":"code","source":["# Parameters\n","\n","# input to rnncell : 3 * 8 * 10\n","# This comment out are para settings used in implementation testing\n","# batch_size = 3\n","# seq_len = 8\n","# input_size = 10\n","# hidden_size = 2\n","# num_layers = 1\n","# one_hot_vec_dim = 129\n","# output_size = 15\n","#-----------------------------------------------------------------------------------------------------\n","\n","\n","# This are para settings for sovling task\n","batch_size = 256\n","seq_len = 8     #  latter we do not feed this to model, model has to compute it by itself\n","hidden_size = 100\n","input_size = 10   \n","num_layers = 2\n","one_hot_vec_dim = 129\n","output_size = 18  # when countries_dic is 1 indexed , output_size has to be 18+1\n","bidirectional=True\n","\n","if bidirectional==True :\n","  D = 2 \n","else:\n","  D =1\n","print(D)\n","\n","\n","class Model_GRU(torch.nn.Module):\n","  def __init__(self, input_size, output_size,hidden_size, batch_size,num_layers,one_hot_vec_dim,bidirectional=bidirectional):\n","    super(Model_GRU, self).__init__()\n","    self.output_size = output_size\n","    self.batch_size = batch_size\n","    self.input_size = input_size\n","    self.hidden_size = hidden_size\n","    self.num_layers = num_layers\n","    self.bidirectional = bidirectional\n","    self.one_hot_vec_dim = one_hot_vec_dim\n","\n","    if bidirectional==True :\n","      D = 2 \n","    else:\n","      D =1\n","\n","    self.embedding = torch.nn.Embedding(num_embeddings=one_hot_vec_dim, embedding_dim=input_size)  \n","    self.rnncell = torch.nn.GRU(input_size, hidden_size, num_layers,bidirectional=bidirectional)\n","    self.fc = torch.nn.Linear(hidden_size * D, output_size)\n","    \n","  def forward(self, input):                          #  : input ( num_Batch:N , sequen_length:L )---> ( N, num_classes )\n","    input = torch.transpose(input,1,0)                   # N,L ---> L,N   256 * 8-->  8 * 256\n","    input = self.embedding(input)                      # L,N --->   ( L, N, Hidden:H ): 8*256--->8* 256 *10\n","    hidden = self.init_hidden()                       # ---> ( D*num_layers, N, H)\n","    out,hidden = self.rnncell(input, hidden)                # L,N,H ; D*num_layers,N,H--->  ( num_layers*D , N , H )\n","\n","    if bidirectional==True:\n","      hidden_cat = torch.cat([hidden[-1],hidden[-2]], dim=1)       # ( num_layers*D , N , H)---> ( N,D*H )\n","    else:\n","      hidden_cat = hidden[-1]                       # ( num_layers*D , N , H)---> ( N,D*H )\n","\n","    fc_output = self.fc(hidden_cat)                     # ( N,D*H ) ---> (N x num_classes)\n","    return fc_output\n","\n","  def init_hidden(self):\n","    hidden = torch.zeros(D* num_layers, batch_size, hidden_size)\n","    return hidden.to(device) \n","    "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"60QkIWWCSCjg","executionInfo":{"status":"ok","timestamp":1676804970143,"user_tz":-60,"elapsed":425,"user":{"displayName":"liam pan","userId":"04789786804288950917"}},"outputId":"3049c285-0586-4f87-c9fd-a1a08f6e31b3"},"execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":["2\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"euFhfa9A2Fov","executionInfo":{"status":"ok","timestamp":1676803437737,"user_tz":-60,"elapsed":9,"user":{"displayName":"liam pan","userId":"04789786804288950917"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["### Test of model "],"metadata":{"id":"ysBBBtdmhdwu"}},{"cell_type":"code","source":["\n","# Instantiate a Model\n","RNNNet_with_GRU = Model_GRU(input_size,output_size, hidden_size, batch_size,num_layers,one_hot_vec_dim=one_hot_vec_dim,bidirectional=bidirectional).to(device)\n","# hidden = torch.zeros(2,3,2)\n","# Feed seq_tensor into it seq_tensor: N x L= 3 x 8 ---> out , hidden\n","\n","# make a input that suits to the new para settings\n","\n","seq_tensor = torch.zeros(56,8).long().to(device)  # ---> input: (num_Batch,sequen_length)\n","# seq_tensor.device\n","\n","prediction_ = RNNNet_with_GRU.forward(seq_tensor)\n","# print('*'*30)\n","# print('output tensor shape: L x Batch x H*D')\n","# print(out.shape)\n","print('*'*30)\n","print('prediction_ tensor shape:   Batch x num_classes')\n","print(prediction_.shape)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0DeCcw7mTt_3","executionInfo":{"status":"ok","timestamp":1676808281201,"user_tz":-60,"elapsed":437,"user":{"displayName":"liam pan","userId":"04789786804288950917"}},"outputId":"04202841-c339-4085-b667-cca0ec0f6a7d"},"execution_count":138,"outputs":[{"output_type":"stream","name":"stdout","text":["******************************\n","prediction_ tensor shape:   Batch x num_classes\n","torch.Size([56, 18])\n"]}]},{"cell_type":"markdown","source":["## **Initialize model**"],"metadata":{"id":"DH_Pi8q5JNO8"}},{"cell_type":"code","source":["RNNNet_with_GRU_1 = Model_GRU(input_size,output_size, hidden_size, batch_size,num_layers,one_hot_vec_dim=one_hot_vec_dim,bidirectional=bidirectional).to(device)\n","RNNNet_with_GRU = RNNNet_with_GRU_1"],"metadata":{"id":"KodOc05TJRus","executionInfo":{"status":"ok","timestamp":1676805451910,"user_tz":-60,"elapsed":1065,"user":{"displayName":"liam pan","userId":"04789786804288950917"}}},"execution_count":79,"outputs":[]},{"cell_type":"markdown","source":["### Define:  Optimizer and Loss"],"metadata":{"id":"KovY-PzHiPU-"}},{"cell_type":"code","source":["# Initialize Model &Loss & Optimizer\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(RNNNet_with_GRU.parameters(), lr=0.001) # lr=0.05\n"],"metadata":{"id":"3NQWXazGiOkY","executionInfo":{"status":"ok","timestamp":1676805453418,"user_tz":-60,"elapsed":6,"user":{"displayName":"liam pan","userId":"04789786804288950917"}}},"execution_count":80,"outputs":[]},{"cell_type":"markdown","source":["# Training Cycle\n"],"metadata":{"id":"uJQt0UktxmF7"}},{"cell_type":"markdown","source":["####Encapsulize test block as a function\n","\n","\n","this two functions might be Wrong, it needs further looks"],"metadata":{"id":"6a91Quefkefn"}},{"cell_type":"markdown","source":["##### Declarations of train() and test()"],"metadata":{"id":"CSfVkKDG_CiT"}},{"cell_type":"code","source":["epoch_list=[]\n","accuracy_list=[]\n","loss_list =[]\n","\n","def train(epoch):\n","  running_loss = 0.0\n","  for batch_idx,data in enumerate(trainloader,1):  # data starts with index 0\n","    names, countries = data  \n","    seq_tensor,seq_lenths,countries = make_tensors(names, countries)\n","\n","    # Forward\n","    countries_pred = RNNNet_with_GRU(seq_tensor)\n","    \n","    # For Debugging purpose\n","    #print(countries_pred.shape)\n","    #print(countries.shape)\n","    loss = criterion(countries_pred,countries)\n","    \n","    # Backward & zeroing previous gradient\n","    optimizer.zero_grad()# before backwards, gradient is set to ZERO again so it doenst influents next iteration,otherwise it will accumulate\n","    loss.backward()#bp计算 weights 的gradient\n","\n","    # gradient clipping\n","    torch.nn.utils.clip_grad_norm(RNNNet_with_GRU_1.parameters(),max_norm=1)\n","    # Update\n","    optimizer.step()\n","    # record loss\n","    running_loss += loss.item()\n","    \n","    #print outcome after each time 300 iteration has been done\n","    if batch_idx % 32 == 0:\n","      print('[%d,%5d]loss:%.3f'%(epoch+1,batch_idx + 1,running_loss/300))\n","      running_loss = 0.0\n","  epoch_list.append(epoch)\n","  loss_list.append(running_loss)\n","  print(running_loss)\n","\n","\n","# Definition of Test\n","\n","def test():\n","  correct = 0\n","  total = 0\n","  with torch.no_grad():   #  这样申明则后面的计算中不会再计算梯度\n","    for batch_idx,data in enumerate(testloader,1):\n","      names, countries = data  \n","      seq_tensor,seq_lenths,countries = make_tensors(names, countries)\n","      # Only for debugging purpose\n","      #print(seq_tensor.shape) # N,L\n","\n","      outputs = RNNNet_with_GRU(seq_tensor) #输出的每一行对应每一图像对各个分类的概率\n","      __,predicted = torch.max(outputs.data,dim = 1)  # 求每一行最大值的下标★ 取得最大值的index放在predicated 中  ★\n","                                # max returns ： 1. the actual maximum，2. its index\n","      total += countries.size(0)   # labels.size = [N,1]\n","      correct += (predicted ==countries).sum().item()\n","  print('Accuracy on test set:%d %%' %(100*correct/total))  # 百分比输出格式\n","  \n","  accuracy_list.append(correct/total)"],"metadata":{"id":"5rZxZe56x5Fp","executionInfo":{"status":"ok","timestamp":1676805475721,"user_tz":-60,"elapsed":429,"user":{"displayName":"liam pan","userId":"04789786804288950917"}}},"execution_count":82,"outputs":[]},{"cell_type":"markdown","source":["##### Test case of function test()\n","\n","problem found , you need to activate drop last=True in trainloader definition, otherwise the rest of data can not form a full batch and is not fit to network setting ,it therefore triggered a errror"],"metadata":{"id":"KgxDICu46CF_"}},{"cell_type":"code","source":["\n","test() # after new configuration in testloader with drop_last =True ,it is working"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LlLMZOo4wosU","executionInfo":{"status":"ok","timestamp":1676805479586,"user_tz":-60,"elapsed":585,"user":{"displayName":"liam pan","userId":"04789786804288950917"}},"outputId":"594a9657-d136-4b94-a2c2-488f5fc5f148"},"execution_count":83,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy on test set:1 %\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-77-10e6e0ca6cd4>:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  countries = torch.tensor(countries).long()\n"]}]},{"cell_type":"markdown","source":["#####Test case of Train()\n","\n","Error: Target 18 is out of bounds. **solved** by setting y_batch from 0idex to 1index\n","https://discuss.pytorch.org/t/indexerror-target-is-out-of-bounds/84417\n","\n","\n"," "],"metadata":{"id":"xMYSTdKO7IcI"}},{"cell_type":"code","source":["train(epoch=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nCfl5njX7MIh","executionInfo":{"status":"ok","timestamp":1676805494886,"user_tz":-60,"elapsed":1711,"user":{"displayName":"liam pan","userId":"04789786804288950917"}},"outputId":"11d4ecc0-57e9-4a80-8de0-a84945235ea5"},"execution_count":84,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-77-10e6e0ca6cd4>:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  countries = torch.tensor(countries).long()\n","<ipython-input-82-40e5f0b64951>:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n","  torch.nn.utils.clip_grad_norm(RNNNet_with_GRU_1.parameters(),max_norm=1)\n"]},{"output_type":"stream","name":"stdout","text":["[2,   33]loss:0.219\n","36.82845902442932\n"]}]},{"cell_type":"markdown","source":["###Bring everything together"],"metadata":{"id":"whrND74LGX3c"}},{"cell_type":"code","source":["acc_list=[]\n","for epoch in range(20):\n","  # Train cycle\n","  train(30)\n","  acc = test()\n","  acc_list.append(acc)"],"metadata":{"id":"QT_Ti9GUGa9Z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676805515009,"user_tz":-60,"elapsed":15216,"user":{"displayName":"liam pan","userId":"04789786804288950917"}},"outputId":"14c1ce47-c776-4141-96e8-a7ce57c25dba"},"execution_count":85,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-77-10e6e0ca6cd4>:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  countries = torch.tensor(countries).long()\n","<ipython-input-82-40e5f0b64951>:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n","  torch.nn.utils.clip_grad_norm(RNNNet_with_GRU_1.parameters(),max_norm=1)\n"]},{"output_type":"stream","name":"stdout","text":["[31,   33]loss:0.198\n","36.72402501106262\n","Accuracy on test set:47 %\n","[31,   33]loss:0.199\n","36.464948415756226\n","Accuracy on test set:47 %\n","[31,   33]loss:0.197\n","37.01613962650299\n","Accuracy on test set:47 %\n","[31,   33]loss:0.198\n","36.861807346343994\n","Accuracy on test set:47 %\n","[31,   33]loss:0.198\n","36.77560007572174\n","Accuracy on test set:47 %\n","[31,   33]loss:0.196\n","37.256418228149414\n","Accuracy on test set:47 %\n","[31,   33]loss:0.194\n","37.708799958229065\n","Accuracy on test set:47 %\n","[31,   33]loss:0.195\n","37.54996883869171\n","Accuracy on test set:47 %\n","[31,   33]loss:0.198\n","36.6327942609787\n","Accuracy on test set:47 %\n","[31,   33]loss:0.196\n","37.11311388015747\n","Accuracy on test set:47 %\n","[31,   33]loss:0.196\n","37.19072151184082\n","Accuracy on test set:47 %\n","[31,   33]loss:0.196\n","37.09042835235596\n","Accuracy on test set:47 %\n","[31,   33]loss:0.197\n","36.93521225452423\n","Accuracy on test set:47 %\n","[31,   33]loss:0.198\n","36.59906566143036\n","Accuracy on test set:47 %\n","[31,   33]loss:0.197\n","36.68087577819824\n","Accuracy on test set:47 %\n","[31,   33]loss:0.196\n","36.99838626384735\n","Accuracy on test set:47 %\n","[31,   33]loss:0.196\n","37.0695515871048\n","Accuracy on test set:47 %\n","[31,   33]loss:0.196\n","37.29087018966675\n","Accuracy on test set:47 %\n","[31,   33]loss:0.196\n","36.99340534210205\n","Accuracy on test set:47 %\n","[31,   33]loss:0.197\n","36.783857464790344\n","Accuracy on test set:47 %\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","# This are para settings for sovling task\n","batch_size = 256\n","seq_len = 8     #  latter we do not feed this to model, model has to compute it by itself\n","hidden_size = 100\n","input_size = 10   \n","num_layers = 2\n","one_hot_vec_dim = 129\n","output_size = 18  # when countries_dic is 1 indexed , output_size has to be 18+1\n","bidirectional=True\n","\n","\n","\n","\n","if __name__ == '__main__':\n","  classifier = Model_GRU(input_size,output_size, hidden_size, batch_size,num_layers=2,one_hot_vec_dim=one_hot_vec_dim,bidirectional=bidirectional)\n","  if USE_GPU:\n","    device = torch.device(\"cuda:0\")\n","    classifier.to(device)\n","  criterion = torch.nn.CrossEntropyLoss()\n","  optimizer = torch.optim.Adam(classifier.parameters(), lr=3)\n","\n","  epoch_list=[]\n","  accuracy_list=[]\n","  loss_list =[]\n","  acc_list=[]\n","  for epoch in range(30):\n","    # Train cycle\n","    train(30)\n","    acc = test()\n","    acc_list.append(acc)\n","plt.plot(epoch_list,loss_list)\n","plt.show() "],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"As26UhL-OIyw","executionInfo":{"status":"ok","timestamp":1676805540890,"user_tz":-60,"elapsed":19466,"user":{"displayName":"liam pan","userId":"04789786804288950917"}},"outputId":"48af0295-3669-45ee-f6d2-1bda4bcc39cb"},"execution_count":86,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-77-10e6e0ca6cd4>:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  countries = torch.tensor(countries).long()\n","<ipython-input-82-40e5f0b64951>:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n","  torch.nn.utils.clip_grad_norm(RNNNet_with_GRU_1.parameters(),max_norm=1)\n"]},{"output_type":"stream","name":"stdout","text":["[31,   33]loss:0.199\n","36.26656210422516\n","Accuracy on test set:47 %\n","[31,   33]loss:0.195\n","37.20446968078613\n","Accuracy on test set:47 %\n","[31,   33]loss:0.196\n","36.888649702072144\n","Accuracy on test set:47 %\n","[31,   33]loss:0.197\n","36.76343262195587\n","Accuracy on test set:47 %\n","[31,   33]loss:0.197\n","36.650067925453186\n","Accuracy on test set:47 %\n","[31,   33]loss:0.196\n","36.953712463378906\n","Accuracy on test set:47 %\n","[31,   33]loss:0.197\n","36.60896098613739\n","Accuracy on test set:47 %\n","[31,   33]loss:0.197\n","36.880480885505676\n","Accuracy on test set:47 %\n","[31,   33]loss:0.197\n","36.70532298088074\n","Accuracy on test set:47 %\n","[31,   33]loss:0.194\n","37.44525730609894\n","Accuracy on test set:47 %\n","[31,   33]loss:0.196\n","37.09383535385132\n","Accuracy on test set:47 %\n","[31,   33]loss:0.196\n","37.04644811153412\n","Accuracy on test set:47 %\n","[31,   33]loss:0.197\n","36.745269656181335\n","Accuracy on test set:47 %\n","[31,   33]loss:0.197\n","36.615737438201904\n","Accuracy on test set:47 %\n","[31,   33]loss:0.196\n","37.0247004032135\n","Accuracy on test set:47 %\n","[31,   33]loss:0.197\n","36.6883270740509\n","Accuracy on test set:47 %\n","[31,   33]loss:0.194\n","37.52673268318176\n","Accuracy on test set:47 %\n","[31,   33]loss:0.196\n","37.117700695991516\n","Accuracy on test set:47 %\n","[31,   33]loss:0.197\n","36.87130522727966\n","Accuracy on test set:47 %\n","[31,   33]loss:0.197\n","36.6851247549057\n","Accuracy on test set:47 %\n","[31,   33]loss:0.197\n","36.81585609912872\n","Accuracy on test set:47 %\n","[31,   33]loss:0.197\n","36.82223951816559\n","Accuracy on test set:47 %\n","[31,   33]loss:0.196\n","37.06930494308472\n","Accuracy on test set:47 %\n","[31,   33]loss:0.197\n","36.77911615371704\n","Accuracy on test set:47 %\n","[31,   33]loss:0.197\n","36.70144176483154\n","Accuracy on test set:47 %\n","[31,   33]loss:0.198\n","36.55790150165558\n","Accuracy on test set:47 %\n","[31,   33]loss:0.196\n","37.2506445646286\n","Accuracy on test set:47 %\n","[31,   33]loss:0.198\n","36.48991918563843\n","Accuracy on test set:47 %\n","[31,   33]loss:0.195\n","37.252575516700745\n","Accuracy on test set:47 %\n","[31,   33]loss:0.197\n","36.61154329776764\n","Accuracy on test set:47 %\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["def trainModel():\n","  total_loss = 0\n","  for i, (names, countries) in enumerate(trainloader, 1):\n","    inputs, seq_lengths, target = make_tensors(names, countries)\n","    output = classifier(inputs)  # only for accelarate , seq_lengths)\n","    loss = criterion(output, target)\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    total_loss += loss.item()\n","    if i % 10 == 0:\n","      print(f'[{i * len(inputs)}/{len(trainset)}] ', end='')\n","      print(f'loss={total_loss / (i * len(inputs))}')\n","  return total_loss\n","\n","def testModel():\n","  correct = 0\n","  total = len(testset)\n","  print(\"evaluating trained model ...\")\n","  with torch.no_grad():\n","    for i, (names, countries) in enumerate(testloader, 1):\n","      inputs, seq_lengths, target = make_tensors(names, countries)\n","      output = classifier(inputs)  # only for accelarate , seq_lengths)\n","      pred = output.max(dim=1, keepdim=True)[1]\n","      correct += pred.eq(target.view_as(pred)).sum().item()\n","    percent = '%.2f' % (100 * correct / total)\n","    print(f'Test set: Accuracy {correct}/{total} {percent}%')\n","  return correct / total\n","\n","  "],"metadata":{"id":"Gn5t-oUOWW8X","executionInfo":{"status":"ok","timestamp":1676805649603,"user_tz":-60,"elapsed":421,"user":{"displayName":"liam pan","userId":"04789786804288950917"}}},"execution_count":87,"outputs":[]},{"cell_type":"markdown","source":["# **Encapsulation everything like what is done in CNN-cifar10**"],"metadata":{"id":"PR6cBU8vbS51"}},{"cell_type":"code","source":["# Import\n","import numpy as np\n","import os\n","from os import path\n","from torch.utils.tensorboard import SummaryWriter\n","\n","gpu_available = torch.cuda.is_available()\n","if gpu_available:\n","    device = \"cuda\" \n","    print(\"Cuda is available\")\n","else: \n","  device = \"cpu\"\n","  print(\"CUDA is not available. Execution time on the cpu is slow.\")"],"metadata":{"id":"wtKGSsrYb5cY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676805652532,"user_tz":-60,"elapsed":2,"user":{"displayName":"liam pan","userId":"04789786804288950917"}},"outputId":"4d68a78a-e0a3-4840-e455-8ab7ec78395a"},"execution_count":88,"outputs":[{"output_type":"stream","name":"stdout","text":["Cuda is available\n"]}]},{"cell_type":"code","source":["# 生成log文件保存的目录文件夹\n","path_to_logs = \"myLogs\"\n","path_to_models = \"myModels\"\n","path_to_data = \"data\"   #  运行后目录下出现三个对应名字的文件夹\n","\n","\n","# Safe directory creation\n","def mksafe_dir(path):\n","    if not os.path.isdir(path):\n","        os.makedirs(path)\n","\n","# Make directories if not already available\n","for directory in [path_to_logs, path_to_models, path_to_data]:\n","    mksafe_dir(directory)"],"metadata":{"id":"l_C2FL5vb27j","executionInfo":{"status":"ok","timestamp":1676805655235,"user_tz":-60,"elapsed":418,"user":{"displayName":"liam pan","userId":"04789786804288950917"}}},"execution_count":89,"outputs":[]},{"cell_type":"markdown","source":["### Implementing function： **train_model()**\n","-----------------------------------\n","\n","\n","first need to implement validate functions we ll implment it after validations_funcions()"],"metadata":{"id":"00jnC0fseEL-"}},{"cell_type":"markdown","source":["##### This is the default criterion we use:\n","--------------------------------\n"],"metadata":{"id":"oJxkqOeyyI00"}},{"cell_type":"code","source":["criterion = torch.nn.CrossEntropyLoss()\n"],"metadata":{"id":"5NpyUZKRyJBJ","executionInfo":{"status":"ok","timestamp":1676805658182,"user_tz":-60,"elapsed":415,"user":{"displayName":"liam pan","userId":"04789786804288950917"}}},"execution_count":90,"outputs":[]},{"cell_type":"markdown","source":["the following is a script what has to be done in that model\n","\n","\n","1.   model paramter settings\n","2.   model trainning settings\n","3.   initialize model\n","4.   \n","\n"],"metadata":{"id":"DwBcO8e1cUrW"}},{"cell_type":"markdown","source":["### Implement **Validation of single batch()** & **Validate_model()**"],"metadata":{"id":"RwEPCA7pAY0R"}},{"cell_type":"markdown","source":["#### Possible Improvement in validation of single batch() & validate_model()\n","\n","\n","\n","1. A better way is to remove that maketensor_part in model.forward and validate)single batch fun, and then place maketensor at the beginning in the for loop of the train block\n","\n","\n","2. For validate_Model it is better to include maketensor function inside it\n","---------------------------------------------\n","this could improve codes efficiency but hurt its reusability（ so maybe don make the change is better）"],"metadata":{"id":"97L04W044FzW"}},{"cell_type":"markdown","source":["####Implement : **Validation of single batch （）**"],"metadata":{"id":"0Uk4BqJvgkP1"}},{"cell_type":"code","source":["def validate_single_batch(model: torch.nn.Module, batch, labels):\n","\n","    batch, seq_lengths, labels = make_tensors(batch, labels)\n","    model.eval()\n","    with torch.no_grad():\n","        top_1_accuracy = []\n","        predictions = model.forward(batch)\n","        predictions = predictions.argmax(dim=1,keepdim=True)\n","        top_1 = predictions==labels\n","        top_1 = top_1.type(torch.float)\n","        top_1_accuracy.append(top_1.mean().cpu())\n","    return np.mean(top_1_accuracy)\n","\n"],"metadata":{"id":"euacMALqglp8","executionInfo":{"status":"ok","timestamp":1676805661053,"user_tz":-60,"elapsed":431,"user":{"displayName":"liam pan","userId":"04789786804288950917"}}},"execution_count":91,"outputs":[]},{"cell_type":"markdown","source":["###### **Test** of validate_single_batch"],"metadata":{"id":"OVWkTUZLrr1m"}},{"cell_type":"code","source":["# Test of validate_single_batch\n","dataiter = iter(trainloader)\n","batch_test, labels_test = next(dataiter)\n","#inputs, seq_lengths, target = make_tensors(batch_test, labels_test)\n","\n","result_test = validate_single_batch(RNNNet_with_GRU_1,batch_test, labels_test)\n","result_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bq1AAqqQj07n","executionInfo":{"status":"ok","timestamp":1676806345440,"user_tz":-60,"elapsed":544,"user":{"displayName":"liam pan","userId":"04789786804288950917"}},"outputId":"3df999fa-e486-4ee7-cd92-54b0248091ce"},"execution_count":114,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-77-10e6e0ca6cd4>:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  countries = torch.tensor(countries).long()\n"]},{"output_type":"execute_result","data":{"text/plain":["0.50390625"]},"metadata":{},"execution_count":114}]},{"cell_type":"markdown","source":["####Implement : **Validate_model（）**"],"metadata":{"id":"bL_mdozkr4iE"}},{"cell_type":"code","source":["def validate_model(model: torch.nn.Module, data):\n","    \n","    model.eval()\n","    with torch.no_grad():\n","        top_1_accuracy = []\n","        for batch, labels in data:\n","          batch, seq_lengths, labels = make_tensors(batch, labels)\n","          labels = labels.to(device)\n","          predictions = model(batch.to(device))\n","          predictions = predictions.argmax(dim=1,keepdim=True)  # 区别max 与argmax：argmax 取index\n","          top_1 = predictions==labels\n","          top_1 = top_1.type(torch.float)\n","          top_1_accuracy.append(top_1.mean().cpu())\n","    return np.mean(top_1_accuracy)\n","\n"],"metadata":{"id":"kWTjUR63r6D4","executionInfo":{"status":"ok","timestamp":1676805665727,"user_tz":-60,"elapsed":6,"user":{"displayName":"liam pan","userId":"04789786804288950917"}}},"execution_count":93,"outputs":[]},{"cell_type":"markdown","source":["##### **Test** of validate_model"],"metadata":{"id":"cKDaTcdHr6VL"}},{"cell_type":"code","source":["test_rsult=validate_model(RNNNet_with_GRU_1,trainloader)\n","test_rsult"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DxYmdq9mutlK","executionInfo":{"status":"ok","timestamp":1676806340432,"user_tz":-60,"elapsed":439,"user":{"displayName":"liam pan","userId":"04789786804288950917"}},"outputId":"76bffe1a-2768-4d13-ee5d-2ae68c42579b"},"execution_count":113,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-77-10e6e0ca6cd4>:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  countries = torch.tensor(countries).long()\n"]},{"output_type":"execute_result","data":{"text/plain":["0.4691256"]},"metadata":{},"execution_count":113}]},{"cell_type":"markdown","source":["###  Implementation of **initialize_model()** function"],"metadata":{"id":"wQ2qkNwMD_Sh"}},{"cell_type":"code","source":["\n","\n","\n","def initialize_baseline_model(input_size,output_size, hidden_size, batch_size,num_layers=2,one_hot_vec_dim=one_hot_vec_dim,bidirectional=bidirectional):\n","  baseline_model = Model_GRU(input_size,output_size, hidden_size, batch_size,num_layers=2,one_hot_vec_dim=one_hot_vec_dim,bidirectional=bidirectional)\n","  baseline_model = baseline_model.to(device)\n","  return baseline_model\n","\n"],"metadata":{"id":"7AIXObaRwN31","executionInfo":{"status":"ok","timestamp":1676808153416,"user_tz":-60,"elapsed":410,"user":{"displayName":"liam pan","userId":"04789786804288950917"}}},"execution_count":134,"outputs":[]},{"cell_type":"markdown","source":["###  Implementation of **Train_model()** function"],"metadata":{"id":"Vp8qG47TuZjD"}},{"cell_type":"code","source":["def train_model(epochs, model, dataloader_train, dataloader_val, optimizer, loss_function, writer, val_step=2, identifier=None):\n","  \n","  # this blcok under can not be used for Generalization of other deep learning project so it is commented out by me\n","\n"," # To log the loss\n","  epoch_loss =[]\n","  epoch_acc =[]\n","  for epoch in range(epochs):\n","    \n","    cur_loss = []\n","    cur_acc = [] \n","  \n","    for batch_idx, (batch, labels) in enumerate(dataloader_train,1):\n","      model.train()# set up to train model\n","      batch_1,labels_1 = batch, labels # save it for validate_single_batch, otherwise, both of them gonna be overwritte into tensor form\n","      batch, seq_lengths, labels = make_tensors(batch, labels)\n","      #Reset the optimizer \n","      optimizer.zero_grad()\n","      prediction = model(batch)\n","\n","      #Backpropagate the error\n","      loss = loss_function(prediction,labels)\n","      loss.backward()\n","      #Gradient clipping\n","      torch.nn.utils.clip_grad_norm(model.parameters(),max_norm=1)\n","      #Update the Weights based on the error\n","      optimizer.step()\n","\n","      cur_acc.append(validate_single_batch(model,batch_1,labels_1))  #  us the unswiched form we have make tensor inside validate_single_batchI()\n","      cur_loss.append(loss.item())                  # a better way is to remove that maketensor_part in each fun, and place maketensor at the beginning in the for loop of the train block\n","                                      # for model.forward and validate single_batch ,is better to remove maketensor ,(but so it need to place make tensor and beginning of for loop)\n","    # Validate the model every n-th episode           # For validate_Model it is better to include maketensor function inside it\n","    if epoch % val_step ==0:\n","      val_score= validate_model(model,dataloader_val)\n","      print(f\"Validation score after epoch {epoch}:{val_score:.3f}\")\n","      writer.add_scalar(\"Acc/val\", val_score, epoch//val_step)  #  what does this line do ? \n","    epoch_loss.append(np.mean(cur_loss))\n","    epoch_acc.append(np.mean(cur_acc))\n","\n","    for name, layer in model.named_children():  # how exactly does this part work ?\n","        if hasattr(layer, \"weight\"):\n","            writer.add_histogram(f\"Histogram/{name}\", layer.weight, epoch)\n","            writer.add_histogram(f\"Histogram/{name}\", layer.weight, epoch)\n","    writer.add_scalar(\"Loss/train\", epoch_loss[-1], epoch)\n","    writer.add_scalar(\"Acc/train\", epoch_acc[-1], epoch)\n","\n","    print(f\"Finished epoch {epoch+1}: Average Loss= {epoch_loss[-1]}, Accuracy= {epoch_acc[-1]}\")\n","\n","  return model, epoch_loss, epoch_acc"],"metadata":{"id":"CDYaOaVheEaK","executionInfo":{"status":"ok","timestamp":1676807279976,"user_tz":-60,"elapsed":408,"user":{"displayName":"liam pan","userId":"04789786804288950917"}}},"execution_count":126,"outputs":[]},{"cell_type":"markdown","source":["## **Use the block to train model with variate settings**\n","\n","\n","After implementation of those blocks ， we are ready to train the model with different settings ， when you have somehing to try out， you can make a code block **using the code block under as a pattern.**\n","------------------------\n","in this way each code block will basically not interfere with others\n","I have adapted it from the CNN cifar 10\n","\n"],"metadata":{"id":"PdruqM366Xvz"}},{"cell_type":"markdown","source":["####   1 Basic GRU_MODEL with learnning rate = 0.001\n","\n","\n","\n"],"metadata":{"id":"bc1ya99E7RMb"}},{"cell_type":"code","source":["\n","identifier = 'GRU_lr0001_CE'\n","model_path = path.join(path_to_models, identifier) \n","mksafe_dir(model_path)  # 运行后mymodels 文件夹下会出现一个 名为 GRU_lr0001_CE 的子文件夹\n","\n","# model settings\n","batch_size = 16    #  remember to change the dataloader's batch size after modefied batch size \n","seq_len = 8     #  latter we do not feed this to model, model has to compute it by itself\n","hidden_size = 100\n","input_size = 10   \n","num_layers = 2\n","one_hot_vec_dim = 129\n","output_size = 18  # when countries_dic is 1 indexed , output_size has to be 18+1\n","bidirectional=True\n","\n","\n","# traning settings\n","Learning_rate = 0.0001\n","epochs = 100\n","\n","# initialize model\n","baseline_model_3 = initialize_baseline_model(input_size,output_size, hidden_size, batch_size,num_layers,one_hot_vec_dim=one_hot_vec_dim,bidirectional=bidirectional)\n","writer = SummaryWriter(path.join(path_to_logs, identifier))\n","optimizer = torch.optim.Adam(baseline_model_3.parameters(), Learning_rate)\n","\n","#  Train this is the most important part\n","exp_model, exp_loss, exp_acc=train_model(epochs, baseline_model_3, trainloader, testloader, optimizer, criterion, writer, val_step=2, identifier=identifier)\n","\n","#\n","writer.flush() #Python file method flush() flushes the internal buffer,why used here I dunno\n","torch.save(exp_model, path.join(model_path, identifier + \"_model.pt\"))\n","validation_score = validate_model(exp_model, testloader)\n","\n","print(f\"The {identifier} model has a validation score of {validation_score}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":808},"id":"Dto_Z40Cc6st","executionInfo":{"status":"error","timestamp":1676808456546,"user_tz":-60,"elapsed":68994,"user":{"displayName":"liam pan","userId":"04789786804288950917"}},"outputId":"3a3f03b3-7c97-43be-b677-f03d48bc6c39"},"execution_count":140,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-77-10e6e0ca6cd4>:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  countries = torch.tensor(countries).long()\n","<ipython-input-126-a215cc9f90f2>:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n","  torch.nn.utils.clip_grad_norm(model.parameters(),max_norm=1)\n"]},{"output_type":"stream","name":"stdout","text":["Validation score after epoch 0:0.469\n","Finished epoch 1: Loss= 1.9094114170103016, Accuracy= 0.4651525020599365\n","Finished epoch 2: Loss= 1.8447156125200008, Accuracy= 0.4691616892814636\n","Validation score after epoch 2:0.469\n","Finished epoch 3: Loss= 1.8449839129419383, Accuracy= 0.46893712878227234\n","Finished epoch 4: Loss= 1.846206107967628, Accuracy= 0.46893712878227234\n","Validation score after epoch 4:0.469\n","Finished epoch 5: Loss= 1.8450405178669684, Accuracy= 0.46908682584762573\n","Finished epoch 6: Loss= 1.8450608085015576, Accuracy= 0.46908682584762573\n","Validation score after epoch 6:0.469\n","Finished epoch 7: Loss= 1.8445025313400223, Accuracy= 0.46908682584762573\n","Finished epoch 8: Loss= 1.8441908929876225, Accuracy= 0.46901196241378784\n","Validation score after epoch 8:0.469\n","Finished epoch 9: Loss= 1.8422751338895924, Accuracy= 0.46908682584762573\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-140-57dbe226c14f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#  Train this is the most important part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mexp_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_acc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_model_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midentifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-126-a215cc9f90f2>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(epochs, model, dataloader_train, dataloader_val, optimizer, loss_function, writer, val_step, identifier)\u001b[0m\n\u001b[1;32m     21\u001b[0m       \u001b[0;31m#Backpropagate the error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m       \u001b[0;31m#Gradient clipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[0;32m--> 488\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["GRU_lr001_CE"],"metadata":{"id":"duXUEi0Rh22U"}},{"cell_type":"code","source":["\n","identifier = 'GRU_lr001_CE'\n","model_path = path.join(path_to_models, identifier) \n","mksafe_dir(model_path)  # 运行后mymodels 文件夹下会出现一个 名为 GRU_lr0001_CE 的子文件夹\n","\n","# model settings\n","batch_size = 16\n","seq_len = 8     #  latter we do not feed this to model, model has to compute it by itself\n","hidden_size = 100\n","input_size = 10   \n","num_layers = 2\n","one_hot_vec_dim = 129\n","output_size = 18  # when countries_dic is 1 indexed , output_size has to be 18+1\n","bidirectional=True\n","\n","\n","# traning settings\n","Learning_rate = 0.001\n","epochs = 200\n","\n","# initialize model\n","baseline_model_4 = initialize_baseline_model(input_size,output_size, hidden_size, batch_size,num_layers,one_hot_vec_dim=one_hot_vec_dim,bidirectional=bidirectional)\n","\n","\n","#  wipe weight \n","for layer in baseline_model_4.children():\n","  if hasattr(layer, 'reset_parameters'):\n","       layer.reset_parameters()\n","\n","\n","writer = SummaryWriter(path.join(path_to_logs, identifier))\n","optimizer = torch.optim.Adam(baseline_model_4.parameters(), Learning_rate)\n","\n","#  Train this is the most important part\n","exp_model, exp_loss, exp_acc=train_model(epochs, baseline_model_4, trainloader, testloader, optimizer, criterion, writer, val_step=2, identifier=identifier)\n","\n","#\n","writer.flush() #Python file method flush() flushes the internal buffer,why used here I dunno\n","torch.save(exp_model, path.join(model_path, identifier + \"_model.pt\"))\n","validation_score = validate_model(exp_model, testloader)\n","\n","print(f\"The {identifier} model has a validation score of {validation_score}\")"],"metadata":{"id":"eECtDT2-upRj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676809593458,"user_tz":-60,"elapsed":1121444,"user":{"displayName":"liam pan","userId":"04789786804288950917"}},"outputId":"26c76bc8-5130-46c8-dce1-52c98017dadb"},"execution_count":141,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-77-10e6e0ca6cd4>:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  countries = torch.tensor(countries).long()\n","<ipython-input-126-a215cc9f90f2>:25: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n","  torch.nn.utils.clip_grad_norm(model.parameters(),max_norm=1)\n"]},{"output_type":"stream","name":"stdout","text":["Validation score after epoch 0:0.469\n","Finished epoch 1: Loss= 1.87232125455034, Accuracy= 0.46814653277397156\n","Finished epoch 2: Loss= 1.8516499046080126, Accuracy= 0.46901196241378784\n","Validation score after epoch 2:0.469\n","Finished epoch 3: Loss= 1.850695582778154, Accuracy= 0.46901196241378784\n","Finished epoch 4: Loss= 1.8476154233167272, Accuracy= 0.46901196241378784\n","Validation score after epoch 4:0.469\n","Finished epoch 5: Loss= 1.847134202040598, Accuracy= 0.4691616892814636\n","Finished epoch 6: Loss= 1.8465809288852943, Accuracy= 0.4692365229129791\n","Validation score after epoch 6:0.469\n","Finished epoch 7: Loss= 1.8473206564337907, Accuracy= 0.4691616892814636\n","Finished epoch 8: Loss= 1.8466721927334449, Accuracy= 0.4691616892814636\n","Validation score after epoch 8:0.469\n","Finished epoch 9: Loss= 1.8462540521593152, Accuracy= 0.46901196241378784\n","Finished epoch 10: Loss= 1.8451410262170667, Accuracy= 0.4692365229129791\n","Validation score after epoch 10:0.469\n","Finished epoch 11: Loss= 1.8466904996397966, Accuracy= 0.46901196241378784\n","Finished epoch 12: Loss= 1.8459902534941712, Accuracy= 0.46908682584762573\n","Validation score after epoch 12:0.469\n","Finished epoch 13: Loss= 1.843249634140266, Accuracy= 0.4692365229129791\n","Finished epoch 14: Loss= 1.8451461263045579, Accuracy= 0.46908682584762573\n","Validation score after epoch 14:0.469\n","Finished epoch 15: Loss= 1.846099204717282, Accuracy= 0.46886226534843445\n","Finished epoch 16: Loss= 1.8447963905905536, Accuracy= 0.46901196241378784\n","Validation score after epoch 16:0.469\n","Finished epoch 17: Loss= 1.8439812676635332, Accuracy= 0.46901196241378784\n","Finished epoch 18: Loss= 1.8442875081193661, Accuracy= 0.46893712878227234\n","Validation score after epoch 18:0.469\n","Finished epoch 19: Loss= 1.843474086316046, Accuracy= 0.46901196241378784\n","Finished epoch 20: Loss= 1.8446086096192549, Accuracy= 0.46908682584762573\n","Validation score after epoch 20:0.469\n","Finished epoch 21: Loss= 1.8426603564245259, Accuracy= 0.469311386346817\n","Finished epoch 22: Loss= 1.8445472602358834, Accuracy= 0.46863773465156555\n","Validation score after epoch 22:0.469\n","Finished epoch 23: Loss= 1.8436625807585116, Accuracy= 0.46893712878227234\n","Finished epoch 24: Loss= 1.8432681050843107, Accuracy= 0.46908682584762573\n","Validation score after epoch 24:0.469\n","Finished epoch 25: Loss= 1.844085414680892, Accuracy= 0.46908682584762573\n","Finished epoch 26: Loss= 1.8425901797717203, Accuracy= 0.4691616892814636\n","Validation score after epoch 26:0.469\n","Finished epoch 27: Loss= 1.8428395277725722, Accuracy= 0.46901196241378784\n","Finished epoch 28: Loss= 1.842815215002277, Accuracy= 0.46886226534843445\n","Validation score after epoch 28:0.469\n","Finished epoch 29: Loss= 1.8446196432599051, Accuracy= 0.46893712878227234\n","Finished epoch 30: Loss= 1.8436181770827242, Accuracy= 0.46908682584762573\n","Validation score after epoch 30:0.469\n","Finished epoch 31: Loss= 1.8428152584030242, Accuracy= 0.46886226534843445\n","Finished epoch 32: Loss= 1.8415236854267691, Accuracy= 0.4692365229129791\n","Validation score after epoch 32:0.469\n","Finished epoch 33: Loss= 1.843565599218814, Accuracy= 0.46901196241378784\n","Finished epoch 34: Loss= 1.842269762618813, Accuracy= 0.46893712878227234\n","Validation score after epoch 34:0.469\n","Finished epoch 35: Loss= 1.8437377342206989, Accuracy= 0.46901196241378784\n","Finished epoch 36: Loss= 1.8413829707100007, Accuracy= 0.4691616892814636\n","Validation score after epoch 36:0.469\n","Finished epoch 37: Loss= 1.8421713647014366, Accuracy= 0.4691616892814636\n","Finished epoch 38: Loss= 1.8423990026919428, Accuracy= 0.46893712878227234\n","Validation score after epoch 38:0.469\n","Finished epoch 39: Loss= 1.842756187130591, Accuracy= 0.46878743171691895\n","Finished epoch 40: Loss= 1.8419179214688832, Accuracy= 0.46893712878227234\n","Validation score after epoch 40:0.469\n","Finished epoch 41: Loss= 1.8421377007118955, Accuracy= 0.46875935792922974\n","Finished epoch 42: Loss= 1.8421581506729126, Accuracy= 0.46893712878227234\n","Validation score after epoch 42:0.469\n","Finished epoch 43: Loss= 1.8439352118326517, Accuracy= 0.46878743171691895\n","Finished epoch 44: Loss= 1.8428870025509132, Accuracy= 0.46893712878227234\n","Validation score after epoch 44:0.469\n","Finished epoch 45: Loss= 1.8417396198489708, Accuracy= 0.46886226534843445\n","Finished epoch 46: Loss= 1.8410693635483701, Accuracy= 0.46886226534843445\n","Validation score after epoch 46:0.469\n","Finished epoch 47: Loss= 1.8413624654986902, Accuracy= 0.46901196241378784\n","Finished epoch 48: Loss= 1.8414519812532528, Accuracy= 0.46893712878227234\n","Validation score after epoch 48:0.469\n","Finished epoch 49: Loss= 1.8413003169133992, Accuracy= 0.4688950181007385\n","Finished epoch 50: Loss= 1.8422875089559727, Accuracy= 0.46886226534843445\n","Validation score after epoch 50:0.469\n","Finished epoch 51: Loss= 1.8409358859776024, Accuracy= 0.4691616892814636\n","Finished epoch 52: Loss= 1.840492776125491, Accuracy= 0.4688716232776642\n","Validation score after epoch 52:0.469\n","Finished epoch 53: Loss= 1.8411612385761238, Accuracy= 0.469311386346817\n","Finished epoch 54: Loss= 1.8391371494995619, Accuracy= 0.46886226534843445\n","Validation score after epoch 54:0.469\n","Finished epoch 55: Loss= 1.8414195162093567, Accuracy= 0.4691616892814636\n","Finished epoch 56: Loss= 1.8412672932276468, Accuracy= 0.46908682584762573\n","Validation score after epoch 56:0.469\n","Finished epoch 57: Loss= 1.8409330999066016, Accuracy= 0.4692365229129791\n","Finished epoch 58: Loss= 1.841119040272193, Accuracy= 0.469311386346817\n","Validation score after epoch 58:0.469\n","Finished epoch 59: Loss= 1.8408168862679761, Accuracy= 0.46908682584762573\n","Finished epoch 60: Loss= 1.8410382570620782, Accuracy= 0.46886226534843445\n","Validation score after epoch 60:0.469\n","Finished epoch 61: Loss= 1.8417453493900642, Accuracy= 0.46893712878227234\n","Finished epoch 62: Loss= 1.8416032340712176, Accuracy= 0.46878743171691895\n","Validation score after epoch 62:0.469\n","Finished epoch 63: Loss= 1.8398425490556363, Accuracy= 0.4688529074192047\n","Finished epoch 64: Loss= 1.8396193461503811, Accuracy= 0.469311386346817\n","Validation score after epoch 64:0.469\n","Finished epoch 65: Loss= 1.8384009808837296, Accuracy= 0.4691616892814636\n","Finished epoch 66: Loss= 1.841836611667793, Accuracy= 0.46886226534843445\n","Validation score after epoch 66:0.469\n","Finished epoch 67: Loss= 1.8384362848219042, Accuracy= 0.46901196241378784\n","Finished epoch 68: Loss= 1.8400211096523764, Accuracy= 0.46871256828308105\n","Validation score after epoch 68:0.469\n","Finished epoch 69: Loss= 1.840661483467696, Accuracy= 0.46893712878227234\n","Finished epoch 70: Loss= 1.841098959788591, Accuracy= 0.46878743171691895\n","Validation score after epoch 70:0.469\n","Finished epoch 71: Loss= 1.8394126773594381, Accuracy= 0.4691616892814636\n","Finished epoch 72: Loss= 1.8399151923413761, Accuracy= 0.46878743171691895\n","Validation score after epoch 72:0.469\n","Finished epoch 73: Loss= 1.8394528742321952, Accuracy= 0.4691616892814636\n","Finished epoch 74: Loss= 1.8392945317451113, Accuracy= 0.4691616892814636\n","Validation score after epoch 74:0.469\n","Finished epoch 75: Loss= 1.839378566656284, Accuracy= 0.46908682584762573\n","Finished epoch 76: Loss= 1.83891785858634, Accuracy= 0.46908682584762573\n","Validation score after epoch 76:0.469\n","Finished epoch 77: Loss= 1.840408393080363, Accuracy= 0.46893712878227234\n","Finished epoch 78: Loss= 1.8400188006326823, Accuracy= 0.46901196241378784\n","Validation score after epoch 78:0.469\n","Finished epoch 79: Loss= 1.8384274666894695, Accuracy= 0.46908682584762573\n","Finished epoch 80: Loss= 1.840070442810744, Accuracy= 0.46886226534843445\n","Validation score after epoch 80:0.469\n","Finished epoch 81: Loss= 1.8376490059726966, Accuracy= 0.46901196241378784\n","Finished epoch 82: Loss= 1.8406826314811935, Accuracy= 0.46908682584762573\n","Validation score after epoch 82:0.469\n","Finished epoch 83: Loss= 1.8401154186911213, Accuracy= 0.46878743171691895\n","Finished epoch 84: Loss= 1.8393389653302952, Accuracy= 0.46878743171691895\n","Validation score after epoch 84:0.469\n","Finished epoch 85: Loss= 1.83918008797183, Accuracy= 0.4691616892814636\n","Finished epoch 86: Loss= 1.8382134002125905, Accuracy= 0.46908682584762573\n","Validation score after epoch 86:0.469\n","Finished epoch 87: Loss= 1.8388802753237192, Accuracy= 0.46901196241378784\n","Finished epoch 88: Loss= 1.8413455836787196, Accuracy= 0.46908682584762573\n","Validation score after epoch 88:0.469\n","Finished epoch 89: Loss= 1.8403697749097905, Accuracy= 0.46878743171691895\n","Finished epoch 90: Loss= 1.8394827876262323, Accuracy= 0.46893712878227234\n","Validation score after epoch 90:0.469\n","Finished epoch 91: Loss= 1.8401928090763664, Accuracy= 0.46893712878227234\n","Finished epoch 92: Loss= 1.839043224428942, Accuracy= 0.46901196241378784\n","Validation score after epoch 92:0.469\n","Finished epoch 93: Loss= 1.8392000742301255, Accuracy= 0.469311386346817\n","Finished epoch 94: Loss= 1.840630031345847, Accuracy= 0.46878743171691895\n","Validation score after epoch 94:0.469\n","Finished epoch 95: Loss= 1.835950784768887, Accuracy= 0.46897923946380615\n","Finished epoch 96: Loss= 1.8386865862115414, Accuracy= 0.46908682584762573\n","Validation score after epoch 96:0.469\n","Finished epoch 97: Loss= 1.8395551420971306, Accuracy= 0.46893712878227234\n","Finished epoch 98: Loss= 1.837312396200831, Accuracy= 0.46893712878227234\n","Validation score after epoch 98:0.469\n","Finished epoch 99: Loss= 1.8393448247167166, Accuracy= 0.46896520256996155\n","Finished epoch 100: Loss= 1.8387301224434447, Accuracy= 0.46886226534843445\n","Validation score after epoch 100:0.469\n","Finished epoch 101: Loss= 1.8387276889321333, Accuracy= 0.46878743171691895\n","Finished epoch 102: Loss= 1.8385854200688665, Accuracy= 0.46908682584762573\n","Validation score after epoch 102:0.469\n","Finished epoch 103: Loss= 1.8382322881036175, Accuracy= 0.46901196241378784\n","Finished epoch 104: Loss= 1.8392184524479027, Accuracy= 0.46893712878227234\n","Validation score after epoch 104:0.469\n","Finished epoch 105: Loss= 1.8382226311518046, Accuracy= 0.46901196241378784\n","Finished epoch 106: Loss= 1.8393835591698835, Accuracy= 0.46901196241378784\n","Validation score after epoch 106:0.469\n","Finished epoch 107: Loss= 1.8383537854263168, Accuracy= 0.4691616892814636\n","Finished epoch 108: Loss= 1.837735493739922, Accuracy= 0.46901196241378784\n","Validation score after epoch 108:0.469\n","Finished epoch 109: Loss= 1.8384138474921266, Accuracy= 0.46893712878227234\n","Finished epoch 110: Loss= 1.8401780575335382, Accuracy= 0.46908682584762573\n","Validation score after epoch 110:0.469\n","Finished epoch 111: Loss= 1.8382809179985595, Accuracy= 0.46886226534843445\n","Finished epoch 112: Loss= 1.8376211251327377, Accuracy= 0.4687827527523041\n","Validation score after epoch 112:0.469\n","Finished epoch 113: Loss= 1.8376557457232903, Accuracy= 0.46893712878227234\n","Finished epoch 114: Loss= 1.835484322031101, Accuracy= 0.46908682584762573\n","Validation score after epoch 114:0.469\n","Finished epoch 115: Loss= 1.839036963228694, Accuracy= 0.46901196241378784\n","Finished epoch 116: Loss= 1.8387709476990615, Accuracy= 0.46901196241378784\n","Validation score after epoch 116:0.469\n","Finished epoch 117: Loss= 1.8375457530963921, Accuracy= 0.46901196241378784\n","Finished epoch 118: Loss= 1.8391817489783922, Accuracy= 0.4691616892814636\n","Validation score after epoch 118:0.469\n","Finished epoch 119: Loss= 1.8382623834524325, Accuracy= 0.46886226534843445\n","Finished epoch 120: Loss= 1.835820650055023, Accuracy= 0.46901196241378784\n","Validation score after epoch 120:0.469\n","Finished epoch 121: Loss= 1.8397755092489505, Accuracy= 0.46908682584762573\n","Finished epoch 122: Loss= 1.8372885274316022, Accuracy= 0.46886226534843445\n","Validation score after epoch 122:0.469\n","Finished epoch 123: Loss= 1.8371225002996936, Accuracy= 0.46878743171691895\n","Finished epoch 124: Loss= 1.8368662433709928, Accuracy= 0.46901196241378784\n","Validation score after epoch 124:0.469\n","Finished epoch 125: Loss= 1.8395329251260815, Accuracy= 0.46886226534843445\n","Finished epoch 126: Loss= 1.8378529270965895, Accuracy= 0.46893712878227234\n","Validation score after epoch 126:0.469\n","Finished epoch 127: Loss= 1.836808931470631, Accuracy= 0.46893712878227234\n","Finished epoch 128: Loss= 1.836888858301197, Accuracy= 0.46886226534843445\n","Validation score after epoch 128:0.469\n","Finished epoch 129: Loss= 1.836810184381679, Accuracy= 0.46875\n","Finished epoch 130: Loss= 1.8368305664576456, Accuracy= 0.46893712878227234\n","Validation score after epoch 130:0.469\n","Finished epoch 131: Loss= 1.837264508116031, Accuracy= 0.46886226534843445\n","Finished epoch 132: Loss= 1.8356688410936002, Accuracy= 0.46886226534843445\n","Validation score after epoch 132:0.469\n","Finished epoch 133: Loss= 1.8372415994455715, Accuracy= 0.46901196241378784\n","Finished epoch 134: Loss= 1.8367959731353258, Accuracy= 0.46901196241378784\n","Validation score after epoch 134:0.469\n","Finished epoch 135: Loss= 1.834911449440939, Accuracy= 0.4691616892814636\n","Finished epoch 136: Loss= 1.8373413721244491, Accuracy= 0.46908682584762573\n","Validation score after epoch 136:0.469\n","Finished epoch 137: Loss= 1.8360305551283373, Accuracy= 0.46863773465156555\n","Finished epoch 138: Loss= 1.839200322142618, Accuracy= 0.46878743171691895\n","Validation score after epoch 138:0.469\n","Finished epoch 139: Loss= 1.835540234614275, Accuracy= 0.46886226534843445\n","Finished epoch 140: Loss= 1.8375921904683827, Accuracy= 0.46871256828308105\n","Validation score after epoch 140:0.469\n","Finished epoch 141: Loss= 1.8360180042461007, Accuracy= 0.46908682584762573\n","Finished epoch 142: Loss= 1.8373281089131703, Accuracy= 0.46901196241378784\n","Validation score after epoch 142:0.469\n","Finished epoch 143: Loss= 1.8401107865179371, Accuracy= 0.46878743171691895\n","Finished epoch 144: Loss= 1.833387584172323, Accuracy= 0.4691616892814636\n","Validation score after epoch 144:0.469\n","Finished epoch 145: Loss= 1.8357299282165345, Accuracy= 0.46908682584762573\n","Finished epoch 146: Loss= 1.8383232616378875, Accuracy= 0.46893712878227234\n","Validation score after epoch 146:0.469\n","Finished epoch 147: Loss= 1.8345883526487978, Accuracy= 0.46886226534843445\n","Finished epoch 148: Loss= 1.8356915877964681, Accuracy= 0.46893712878227234\n","Validation score after epoch 148:0.469\n","Finished epoch 149: Loss= 1.8371286023876625, Accuracy= 0.46901196241378784\n","Finished epoch 150: Loss= 1.8366200224368159, Accuracy= 0.46908682584762573\n","Validation score after epoch 150:0.469\n","Finished epoch 151: Loss= 1.8367880469310784, Accuracy= 0.46901196241378784\n","Finished epoch 152: Loss= 1.8384802319332512, Accuracy= 0.46901196241378784\n","Validation score after epoch 152:0.469\n","Finished epoch 153: Loss= 1.8359319975276194, Accuracy= 0.4691616892814636\n","Finished epoch 154: Loss= 1.8355949032092522, Accuracy= 0.46893712878227234\n","Validation score after epoch 154:0.469\n","Finished epoch 155: Loss= 1.835113160767241, Accuracy= 0.46908682584762573\n","Finished epoch 156: Loss= 1.8372996720011363, Accuracy= 0.46871256828308105\n","Validation score after epoch 156:0.469\n","Finished epoch 157: Loss= 1.8356468523333886, Accuracy= 0.4692365229129791\n","Finished epoch 158: Loss= 1.8366490670306954, Accuracy= 0.46908682584762573\n","Validation score after epoch 158:0.469\n","Finished epoch 159: Loss= 1.8364792454742387, Accuracy= 0.46901196241378784\n","Finished epoch 160: Loss= 1.8366889943619689, Accuracy= 0.46901196241378784\n","Validation score after epoch 160:0.469\n","Finished epoch 161: Loss= 1.8341592285447492, Accuracy= 0.46908682584762573\n","Finished epoch 162: Loss= 1.8358553041241126, Accuracy= 0.4693862199783325\n","Validation score after epoch 162:0.469\n","Finished epoch 163: Loss= 1.8346283699937924, Accuracy= 0.4691616892814636\n","Finished epoch 164: Loss= 1.837983962233195, Accuracy= 0.46878743171691895\n","Validation score after epoch 164:0.469\n","Finished epoch 165: Loss= 1.8363826910892647, Accuracy= 0.46878743171691895\n","Finished epoch 166: Loss= 1.8338256603229546, Accuracy= 0.46886226534843445\n","Validation score after epoch 166:0.469\n","Finished epoch 167: Loss= 1.8365655610661307, Accuracy= 0.46893712878227234\n","Finished epoch 168: Loss= 1.8343789746661385, Accuracy= 0.46893712878227234\n","Validation score after epoch 168:0.469\n","Finished epoch 169: Loss= 1.838439672864126, Accuracy= 0.46886226534843445\n","Finished epoch 170: Loss= 1.834460358419818, Accuracy= 0.46886226534843445\n","Validation score after epoch 170:0.469\n","Finished epoch 171: Loss= 1.8364233217553465, Accuracy= 0.46901196241378784\n","Finished epoch 172: Loss= 1.8360469856661952, Accuracy= 0.46893712878227234\n","Validation score after epoch 172:0.469\n","Finished epoch 173: Loss= 1.835131524993988, Accuracy= 0.46901196241378784\n","Finished epoch 174: Loss= 1.835668718386553, Accuracy= 0.46901196241378784\n","Validation score after epoch 174:0.469\n","Finished epoch 175: Loss= 1.8357458475107205, Accuracy= 0.46901196241378784\n","Finished epoch 176: Loss= 1.8383817587070121, Accuracy= 0.46901196241378784\n","Validation score after epoch 176:0.469\n","Finished epoch 177: Loss= 1.8362633689434942, Accuracy= 0.46893712878227234\n","Finished epoch 178: Loss= 1.8348655245261278, Accuracy= 0.469311386346817\n","Validation score after epoch 178:0.469\n","Finished epoch 179: Loss= 1.83509622148411, Accuracy= 0.4692365229129791\n","Finished epoch 180: Loss= 1.8342898516597863, Accuracy= 0.46901196241378784\n","Validation score after epoch 180:0.469\n","Finished epoch 181: Loss= 1.8372151802399914, Accuracy= 0.46901196241378784\n","Finished epoch 182: Loss= 1.835713690626407, Accuracy= 0.46893712878227234\n","Validation score after epoch 182:0.469\n","Finished epoch 183: Loss= 1.8354225586274426, Accuracy= 0.46893712878227234\n","Finished epoch 184: Loss= 1.8360660031884017, Accuracy= 0.46908682584762573\n","Validation score after epoch 184:0.469\n","Finished epoch 185: Loss= 1.836523359407208, Accuracy= 0.46901196241378784\n","Finished epoch 186: Loss= 1.8339382227309449, Accuracy= 0.469077467918396\n","Validation score after epoch 186:0.469\n","Finished epoch 187: Loss= 1.837190692724582, Accuracy= 0.46893712878227234\n","Finished epoch 188: Loss= 1.8356120680620571, Accuracy= 0.46886226534843445\n","Validation score after epoch 188:0.469\n","Finished epoch 189: Loss= 1.8356359403290434, Accuracy= 0.46893712878227234\n","Finished epoch 190: Loss= 1.8351114767040322, Accuracy= 0.46901196241378784\n","Validation score after epoch 190:0.469\n","Finished epoch 191: Loss= 1.8367549415120108, Accuracy= 0.46908682584762573\n","Finished epoch 192: Loss= 1.8342617223362723, Accuracy= 0.46893712878227234\n","Validation score after epoch 192:0.469\n","Finished epoch 193: Loss= 1.8354601317537045, Accuracy= 0.46886226534843445\n","Finished epoch 194: Loss= 1.836814462139221, Accuracy= 0.46908682584762573\n","Validation score after epoch 194:0.469\n","Finished epoch 195: Loss= 1.838181948376273, Accuracy= 0.46901196241378784\n","Finished epoch 196: Loss= 1.8364542924001546, Accuracy= 0.4691616892814636\n","Validation score after epoch 196:0.469\n","Finished epoch 197: Loss= 1.8352289741624614, Accuracy= 0.46886226534843445\n","Finished epoch 198: Loss= 1.8370765311989241, Accuracy= 0.46856287121772766\n","Validation score after epoch 198:0.469\n","Finished epoch 199: Loss= 1.834059348077831, Accuracy= 0.46908682584762573\n","Finished epoch 200: Loss= 1.8345892986851537, Accuracy= 0.46893712878227234\n","The GRU_lr001_CE model has a validation score of 0.46889951825141907\n"]}]},{"cell_type":"markdown","source":["#### 2  Speeded up GRU_MODEL with **pack_padded_sequence** ...learnning rate = 0.001\n","-----------------------------------------------------\n","\n","https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pack_padded_sequence.html"],"metadata":{"id":"5Qy8ETPE70pQ"}},{"cell_type":"markdown","source":["# Conclusion & others"],"metadata":{"id":"tgozYUCfx563"}},{"cell_type":"markdown","source":[],"metadata":{"id":"jbz9vZcI_iJY"}},{"cell_type":"markdown","source":["#### A better way to make dictionary"],"metadata":{"id":"wku2e_vIFYlb"}},{"cell_type":"code","source":["list1 =torch.arange(1,5).tolist()\n","countries_list\n","List3 =dict(zip(countries_list,list1))\n","print(List3)\n","\n"],"metadata":{"id":"C0AlSGYAmn8H","executionInfo":{"status":"aborted","timestamp":1676804988189,"user_tz":-60,"elapsed":2,"user":{"displayName":"liam pan","userId":"04789786804288950917"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####  To get index\n","\n","\n","```\n","# output_draft = torch.randn(3,18)\n","print(output_draft.shape)\n","print(output_draft)\n","predictions_draft2 = output_draft.argmax(dim=1,keepdim=True)  # 1.method\n","print(predictions_draft2)\n","___,predictions_draft = output_draft.max(dim=1,keepdim=True)  # 2.method\n","print(predictions_draft)\n","```\n","\n"],"metadata":{"id":"UkTThEBVi1uf"}},{"cell_type":"code","source":["output_draft = torch.randn(3,18)\n","print(output_draft.shape)\n","print(output_draft)\n","predictions_draft2 = output_draft.argmax(dim=1,keepdim=True)\n","print(predictions_draft2)\n","___,predictions_draft = output_draft.max(dim=1,keepdim=True)\n","print(predictions_draft)"],"metadata":{"id":"aUKJWNaShIbe","executionInfo":{"status":"aborted","timestamp":1676804988189,"user_tz":-60,"elapsed":2,"user":{"displayName":"liam pan","userId":"04789786804288950917"}}},"execution_count":null,"outputs":[]}]}